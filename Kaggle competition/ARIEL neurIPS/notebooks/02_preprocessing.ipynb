{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# NeurIPS 2024 Ariel Data Challenge — Preprocessing Pipeline\n\n**Goal**: Demonstrate the full preprocessing pipeline that converts raw telescope photometry into a per-wavelength transit-depth spectrum.\n\n**Pipeline steps**:\n0. Detector calibration — dark subtraction, flat fielding, dead pixel masking, spatial summation (raw parquet → calibrated numpy)\n1. Out-of-transit (OOT) mask — identify which time frames are baseline (no planet)\n2. Baseline normalisation — divide each channel by its OOT median to make flux dimensionless\n3. Common-mode correction — remove correlated systematics shared across all wavelengths\n4. Temporal binning — co-add frames to boost SNR by √bin_size\n5. Transit depth extraction — compute per-channel depth = 1 − ⟨in-transit flux⟩\n6. Full one-liner pipeline — `preprocess_planet()` wraps all steps\n\n**Source module**: `src/preprocessing.py` — all functions are pure numpy, no side effects.\n\n> **Note**: This notebook is Kaggle-ready. Run it as a Kaggle notebook kernel with the `ariel-data-challenge-2024` dataset attached."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess, sys\nfrom pathlib import Path\n\n# ── Kaggle: clone repo and add to sys.path ─────────────────────────────────\nrepo_dir = \"/kaggle/working/ariel-exoplanet-ml\"\nproject_dir = repo_dir + \"/Kaggle competition/ARIEL neurIPS\"\n\nif not Path(repo_dir).exists():\n    subprocess.run(\n        [\"git\", \"clone\", \"https://github.com/Smooth-Cactus0/ariel-exoplanet-ml.git\", repo_dir],\n        check=True,\n    )\n    print(f\"Cloned repo to {repo_dir}\")\nelse:\n    print(f\"Repo already exists at {repo_dir}\")\n\nsys.path.insert(0, project_dir)\n\nDATA_ROOT = \"/kaggle/input/ariel-data-challenge-2024\"\n\nprint(f\"project_dir: {project_dir}\")\nprint(f\"DATA_ROOT  : {DATA_ROOT}\")\nprint(f\"sys.path[0]: {sys.path[0]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom src.preprocessing import (\n    out_of_transit_mask,\n    baseline_normalize,\n    common_mode_correction,\n    bin_time,\n    extract_transit_depth,\n    preprocess_planet,\n)\n\n# ── Plot style ─────────────────────────────────────────────────────────────\nplt.rcParams.update({\n    \"figure.dpi\": 110,\n    \"axes.spines.top\": False,\n    \"axes.spines.right\": False,\n    \"savefig.dpi\": 150,\n    \"savefig.facecolor\": \"white\",\n})\n\n# ── Figure output directory ────────────────────────────────────────────────\nFIG_DIR = Path(\"/kaggle/working/figures_preprocessing\")\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(f\"NumPy      : {np.__version__}\")\nprint(f\"Pandas     : {pd.__version__}\")\nprint(f\"Matplotlib : {matplotlib.__version__}\")\nprint(f\"FIG_DIR    : {FIG_DIR}\")\nprint(\"[Done] All imports successful.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 0: Load and Calibrate One Planet\n\nThe raw data lives in per-planet directories as parquet files:\n\n```\n{data_root}/train/{planet_id}/\n    AIRS-CH0_signal.parquet          (11250, 32*356) uint16\n    FGS1_signal.parquet              (135000, 32*32) uint16\n    AIRS-CH0_calibration/\n        dark.parquet  flat.parquet  dead.parquet  ...\n    FGS1_calibration/\n        dark.parquet  flat.parquet  dead.parquet  ...\n```\n\n**Calibration** converts raw detector counts to science-ready flux:\n1. **Dark subtraction** — remove thermal electron current: `cal = raw - dark`\n2. **Flat-field division** — correct per-pixel sensitivity: `cal /= flat`\n3. **Dead pixel zeroing** — mask bad pixels to zero\n\nAfter calibration, we **sum over the spatial rows** (32 rows for AIRS, 32x32 pixels for FGS1) to collapse the 2-D detector image into 1-D light curves:\n- AIRS: `(n_time, 32, 356)` → `(n_time, 356)` — one flux value per spectral channel per time step\n- FGS1: `(n_time_fgs, 32, 32)` → `(n_time_fgs,)` → downsample 12:1 → `(n_time,)` — broadband flux at AIRS cadence"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\n# ── Detector geometry (confirmed) ──────────────────────────────────────────\nAIRS_N_ROWS = 32    # spatial rows on AIRS-CH0 detector\nAIRS_N_COLS = 356   # spectral channels\nFGS1_N_ROWS = 32\nFGS1_N_COLS = 32\nFGS1_RATIO  = 12    # FGS1 frames per AIRS frame (135000 / 11250)\n\n\ndef calibrate(raw, dark, flat, dead):\n    \"\"\"Apply dark subtraction, flat-field division, and dead pixel zeroing.\"\"\"\n    cal = raw - dark[None]\n    flat_safe = np.where(flat == 0, 1.0, flat)\n    cal /= flat_safe[None]\n    cal[:, dead.astype(bool)] = 0.0\n    return cal\n\n\ndata_root = Path(DATA_ROOT)\ntrain_dir = data_root / \"train\"\n\n# ── Discover planet directories ────────────────────────────────────────────\nplanet_dirs = sorted(\n    [d for d in train_dir.iterdir() if d.is_dir()]\n) if train_dir.exists() else []\n\nprint(f\"Planet directories found: {len(planet_dirs)}\")\nfor d in planet_dirs[:5]:\n    print(f\"  {d.name}\")\nif len(planet_dirs) > 5:\n    print(f\"  ... ({len(planet_dirs) - 5} more)\")\n\nairs = None\nfgs1 = None\nplanet_id = None\n\nif len(planet_dirs) > 0:\n    planet_dir = planet_dirs[0]\n    planet_id = planet_dir.name\n    print(f\"\\nLoading planet '{planet_id}' ...\")\n\n    try:\n        # ── Load and calibrate AIRS-CH0 ────────────────────────────────────\n        raw_airs = (\n            pd.read_parquet(planet_dir / \"AIRS-CH0_signal.parquet\")\n            .values.astype(np.float64)\n        )\n        n_time_airs = raw_airs.shape[0]\n        raw_airs = raw_airs.reshape(n_time_airs, AIRS_N_ROWS, AIRS_N_COLS)\n        print(f\"  AIRS raw shape     : ({n_time_airs}, {AIRS_N_ROWS}, {AIRS_N_COLS})\")\n\n        cal_dir = planet_dir / \"AIRS-CH0_calibration\"\n        dark_airs = pd.read_parquet(cal_dir / \"dark.parquet\").values.astype(np.float64)\n        flat_airs = pd.read_parquet(cal_dir / \"flat.parquet\").values.astype(np.float64)\n        dead_airs = pd.read_parquet(cal_dir / \"dead.parquet\").values\n\n        cal_airs = calibrate(raw_airs, dark_airs, flat_airs, dead_airs)\n        airs = cal_airs.sum(axis=1)  # sum spatial rows → (n_time, 356)\n        print(f\"  AIRS calibrated    : {cal_airs.shape} → summed to {airs.shape}\")\n\n        # ── Load and calibrate FGS1 ───────────────────────────────────────\n        raw_fgs = (\n            pd.read_parquet(planet_dir / \"FGS1_signal.parquet\")\n            .values.astype(np.float64)\n        )\n        n_time_fgs = raw_fgs.shape[0]\n        raw_fgs = raw_fgs.reshape(n_time_fgs, FGS1_N_ROWS, FGS1_N_COLS)\n        print(f\"  FGS1 raw shape     : ({n_time_fgs}, {FGS1_N_ROWS}, {FGS1_N_COLS})\")\n\n        cal_dir_fgs = planet_dir / \"FGS1_calibration\"\n        dark_fgs = pd.read_parquet(cal_dir_fgs / \"dark.parquet\").values.astype(np.float64)\n        flat_fgs = pd.read_parquet(cal_dir_fgs / \"flat.parquet\").values.astype(np.float64)\n        dead_fgs = pd.read_parquet(cal_dir_fgs / \"dead.parquet\").values\n\n        cal_fgs = calibrate(raw_fgs, dark_fgs, flat_fgs, dead_fgs)\n        fgs1_full = cal_fgs.sum(axis=(1, 2))  # sum all pixels → (n_time_fgs,)\n        print(f\"  FGS1 calibrated    : {cal_fgs.shape} → summed to {fgs1_full.shape}\")\n\n        # Downsample FGS1 to AIRS cadence (average every `ratio` frames)\n        ratio = n_time_fgs // n_time_airs\n        if ratio > 1:\n            trimmed = fgs1_full[: n_time_airs * ratio]\n            fgs1 = trimmed.reshape(n_time_airs, ratio).mean(axis=1)\n        else:\n            fgs1 = fgs1_full[:n_time_airs]\n        print(f\"  FGS1 downsampled   : {fgs1_full.shape} → {fgs1.shape}  (ratio={ratio}:1)\")\n\n    except Exception as e:\n        print(f\"Error loading planet data: {e}\")\n        airs = None\n\n# ── Fallback: synthetic data so all cells run offline ─────────────────────\nif airs is None:\n    print(\"\\nNo parquet data found. Generating SYNTHETIC data for offline demonstration.\")\n    rng = np.random.default_rng(42)\n    N_TIME, N_CHAN = 300, 356\n    t_norm = np.linspace(0, 1, N_TIME)\n    # Flat baseline with a ~1% transit dip between 0.2 and 0.8\n    transit_mask_synth = (t_norm >= 0.2) & (t_norm <= 0.8)\n    # Channel-dependent depth: shallow at short wavelengths, deeper at long\n    depth_per_chan = 0.005 + 0.005 * np.linspace(0, 1, N_CHAN)\n    airs = 1e5 * (\n        1.0\n        - transit_mask_synth[:, None] * depth_per_chan[None, :]\n        + rng.normal(0, 0.001, (N_TIME, N_CHAN))\n    )\n    fgs1 = 2e5 * (\n        1.0\n        - transit_mask_synth * 0.008\n        + rng.normal(0, 0.001, N_TIME)\n    )\n    planet_id = \"synthetic-planet-000\"\n    print(f\"  Synthetic AIRS shape : {airs.shape}\")\n    print(f\"  Synthetic FGS1 shape : {fgs1.shape}\")\n\n# Ensure AIRS is (time, wavelength)\nif airs.ndim == 2 and airs.shape[0] < airs.shape[1]:\n    print(f\"Transposing AIRS from {airs.shape} to {airs.T.shape} (guessed orientation)\")\n    airs = airs.T\n\n# Ensure FGS1 is 1-D\nfgs1 = fgs1.ravel()\n\nprint(f\"\\nAIRS shape : {airs.shape}  (time x wavelength)\")\nprint(f\"FGS1 shape : {fgs1.shape}  (time,)\")\nprint(f\"[Done] Loaded planet '{planet_id}'.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Out-of-Transit Mask\n",
    "\n",
    "We define a boolean mask over the time axis that is `True` wherever the planet is **not** in front of the star.\n",
    "\n",
    "- **Ingress fraction**: the normalised time at which the planet disc first overlaps the stellar disc.\n",
    "- **Egress fraction**: the normalised time at which the planet disc last overlaps the stellar disc.\n",
    "- Frames between ingress and egress are **in-transit** (mask = `False`); all others are **out-of-transit** (mask = `True`).\n",
    "\n",
    "The default `ingress=0.2`, `egress=0.8` means the transit occupies the central 60% of the observation window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "INGRESS = 0.2\nEGRESS  = 0.8\n\nn_time = airs.shape[0]\nmask_oot = out_of_transit_mask(n_time, ingress=INGRESS, egress=EGRESS)\n\nn_oot = mask_oot.sum()\nn_it  = (~mask_oot).sum()\n\nprint(f\"Total time steps : {n_time}\")\nprint(f\"OOT frames       : {n_oot}  ({100 * n_oot / n_time:.1f}%)\")\nprint(f\"In-transit frames: {n_it}   ({100 * n_it / n_time:.1f}%)\")\nprint(f\"Ingress fraction : {INGRESS}  (frame {int(INGRESS * n_time)})\")\nprint(f\"Egress fraction  : {EGRESS}   (frame {int(EGRESS * n_time)})\")\n\n# ── Plot the mask as a shaded bar ──────────────────────────────────────────\nfig, ax = plt.subplots(figsize=(12, 2.5))\n\nt_idx = np.arange(n_time)\n\n# Draw OOT (green) and in-transit (red) as filled regions\nax.fill_between(t_idx, 0, 1,\n                where=mask_oot,\n                step=\"mid\",\n                color=\"mediumseagreen\", alpha=0.45, label=\"Out-of-transit (OOT)\")\nax.fill_between(t_idx, 0, 1,\n                where=~mask_oot,\n                step=\"mid\",\n                color=\"tomato\", alpha=0.45, label=\"In-transit\")\n\n# Ingress / egress vertical lines\nax.axvline(INGRESS * n_time, color=\"navy\", lw=1.5, linestyle=\"--\", label=f\"Ingress (t={INGRESS})\")\nax.axvline(EGRESS  * n_time, color=\"darkred\", lw=1.5, linestyle=\"--\", label=f\"Egress  (t={EGRESS})\")\n\nax.set_xlim(0, n_time - 1)\nax.set_ylim(0, 1)\nax.set_xlabel(\"Time index\", fontsize=11)\nax.set_yticks([])\nax.set_title(\n    f\"Out-of-Transit Mask  |  {n_oot} OOT frames (green)  +  {n_it} in-transit frames (red)  |  \"\n    f\"ingress={INGRESS}, egress={EGRESS}\",\n    fontsize=11\n)\nax.legend(loc=\"upper right\", fontsize=9, framealpha=0.9)\n\nplt.tight_layout()\nfig.savefig(FIG_DIR / \"step1_oot_mask.png\", bbox_inches=\"tight\")\nplt.show()\n\nprint(f\"[Done] OOT mask: {n_oot} baseline frames, {n_it} in-transit frames.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Baseline Normalisation\n",
    "\n",
    "Each wavelength channel is divided by its **out-of-transit median**. After normalisation:\n",
    "\n",
    "- OOT flux fluctuates around **1.0** for every channel independently.\n",
    "- In-transit flux dips **below 1.0** by an amount equal to the transit depth `(Rp/Rs)²`.\n",
    "- Absolute detector gain differences between channels are removed.\n",
    "\n",
    "We use the **AIRS white-light curve** (mean across all 356 wavelength channels) to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# White-light curve = mean over all wavelength channels\nairs_white_raw = airs.mean(axis=1)           # (n_time,)\n\n# Baseline normalise the full 2-D cube\nairs_norm = baseline_normalize(airs, mask_oot)  # (n_time, n_chan)\n\n# Normalised white-light\nairs_white_norm = airs_norm.mean(axis=1)      # (n_time,)\n\n# Diagnostics\noot_median_before = np.median(airs_white_raw[mask_oot])\noot_median_after  = np.median(airs_white_norm[mask_oot])\nprint(f\"OOT median (raw)         : {oot_median_before:.4f}\")\nprint(f\"OOT median (normalised)  : {oot_median_after:.6f}  (should be ≈ 1.0)\")\n\nt_idx = np.arange(n_time)\n\nfig, axes = plt.subplots(2, 1, figsize=(12, 7), sharex=True)\nfig.suptitle(\"Baseline Normalisation — AIRS White-Light Curve\", fontsize=13, fontweight=\"bold\")\n\n# ── Raw flux ───────────────────────────────────────────────────────────────\nax0 = axes[0]\nax0.plot(t_idx, airs_white_raw, lw=0.9, color=\"steelblue\", label=\"Raw white-light flux\")\nax0.axhline(oot_median_before, color=\"darkgreen\", lw=1.2, linestyle=\"--\",\n            label=f\"OOT median = {oot_median_before:.4f}\")\nax0.fill_between(t_idx, airs_white_raw.min(), airs_white_raw.max(),\n                 where=~mask_oot, color=\"tomato\", alpha=0.12, label=\"In-transit window\")\nax0.set_ylabel(\"Detector counts\", fontsize=10)\nax0.set_title(\"Raw flux (ADU)\", fontsize=10)\nax0.legend(fontsize=8)\n\n# ── Normalised flux ────────────────────────────────────────────────────────\nax1 = axes[1]\nax1.plot(t_idx, airs_white_norm, lw=0.9, color=\"darkorchid\", label=\"Normalised white-light flux\")\nax1.axhline(1.0, color=\"darkgreen\", lw=1.2, linestyle=\"--\", label=\"OOT median = 1.0\")\nax1.fill_between(t_idx, airs_white_norm.min() * 0.9998, 1.001,\n                 where=~mask_oot, color=\"tomato\", alpha=0.12, label=\"In-transit window\")\nax1.set_xlabel(\"Time index\", fontsize=10)\nax1.set_ylabel(\"Normalised flux\", fontsize=10)\nax1.set_title(\"Normalised flux (dimensionless, OOT ≈ 1.0)\", fontsize=10)\nax1.legend(fontsize=8)\n\nplt.tight_layout()\nfig.savefig(FIG_DIR / \"step2_baseline_normalisation.png\", bbox_inches=\"tight\")\nplt.show()\n\nprint(f\"AIRS normalised cube shape: {airs_norm.shape}\")\nprint(f\"[Done] Baseline normalisation complete. OOT median before={oot_median_before:.4f}, after={oot_median_after:.6f}.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Common-Mode Correction\n",
    "\n",
    "Even after per-channel normalisation, correlated noise can affect every wavelength simultaneously:\n",
    "\n",
    "- Telescope pointing jitter moves the target slightly on the detector.\n",
    "- Thermal \"breathing\" changes the PSF size uniformly across the focal plane.\n",
    "- Stellar variability (granulation, flares) brightens or dims all channels together.\n",
    "\n",
    "The **common mode** is the wavelength-mean light curve at each time step. Dividing by it removes these shared systematics while leaving wavelength-dependent signals (atmospheric absorption lines) intact.\n",
    "\n",
    "> **Key subtlety**: In-transit frames naturally dip below 1.0 (the planet blocks light). If we divided all frames by the raw common mode including this dip, we would accidentally cancel the transit signal we want to measure. Therefore, in-transit common-mode values are **clamped** to the OOT mean before dividing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Common mode = mean over all wavelength channels per time step\ncommon_mode = airs_norm.mean(axis=1)          # (n_time,)\noot_level   = common_mode[mask_oot].mean()    # scalar ≈ 1.0\n\n# Apply common-mode correction\nairs_cmc = common_mode_correction(airs_norm, mask_oot)  # (n_time, n_chan)\n\nt_idx = np.arange(n_time)\n\nfig, axes = plt.subplots(2, 1, figsize=(12, 7), sharex=True)\nfig.suptitle(\"Common-Mode Correction\", fontsize=13, fontweight=\"bold\")\n\n# ── Common-mode signal ─────────────────────────────────────────────────────\nax0 = axes[0]\nax0.plot(t_idx, common_mode, lw=0.9, color=\"darkorange\", label=\"Common-mode signal (λ-mean)\")\nax0.axhline(oot_level, color=\"darkgreen\", lw=1.2, linestyle=\"--\",\n            label=f\"OOT mean = {oot_level:.5f}\")\nax0.fill_between(t_idx, common_mode.min() * 0.9998, oot_level * 1.0002,\n                 where=~mask_oot, color=\"tomato\", alpha=0.15)\nax0.set_ylabel(\"Wavelength-mean flux\", fontsize=10)\nax0.set_title(\"Common-mode signal (mean over all 356 AIRS channels)\", fontsize=10)\nax0.legend(fontsize=8)\n\n# Annotate the clamping\nax0.annotate(\n    \"In-transit values clamped to OOT mean\\nbefore dividing (prevents transit self-subtraction)\",\n    xy=(n_time * 0.5, common_mode[n_time // 2]),\n    xytext=(n_time * 0.62, oot_level + (oot_level - common_mode.min()) * 0.6),\n    arrowprops=dict(arrowstyle=\"->\", color=\"gray\", lw=1.2),\n    fontsize=8, color=\"gray\",\n    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\", edgecolor=\"gray\", alpha=0.8),\n)\n\n# ── CMC white-light curve ──────────────────────────────────────────────────\nax1 = axes[1]\nairs_cmc_white = airs_cmc.mean(axis=1)\nax1.plot(t_idx, airs_cmc_white, lw=0.9, color=\"steelblue\",\n         label=\"CMC-corrected white-light flux\")\nax1.axhline(1.0, color=\"darkgreen\", lw=1.2, linestyle=\"--\", label=\"Expected OOT baseline = 1.0\")\nax1.fill_between(t_idx, airs_cmc_white.min() * 0.9998, 1.001,\n                 where=~mask_oot, color=\"tomato\", alpha=0.12, label=\"In-transit window\")\nax1.set_xlabel(\"Time index\", fontsize=10)\nax1.set_ylabel(\"Normalised flux\", fontsize=10)\nax1.set_title(\"After common-mode correction — correlated systematics removed\", fontsize=10)\nax1.legend(fontsize=8)\n\nplt.tight_layout()\nfig.savefig(FIG_DIR / \"step3_common_mode_correction.png\", bbox_inches=\"tight\")\nplt.show()\n\nprint(f\"Common-mode OOT level : {oot_level:.6f}\")\nprint(f\"CMC cube shape        : {airs_cmc.shape}\")\nprint(f\"[Done] Common-mode correction applied. CMC white-light in-transit depth: \"\n      f\"{1 - airs_cmc_white[~mask_oot].mean():.5f}.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Time Binning\n",
    "\n",
    "Co-adding `bin_size` consecutive frames reduces photon noise by a factor of **√bin_size** (for white noise).\n",
    "\n",
    "With `bin_size=5`:\n",
    "- Time axis shrinks from `n_time` to `n_time // 5` frames.\n",
    "- Expected SNR improvement: **√5 ≈ 2.24×**.\n",
    "- Trailing frames that don't fill a complete bin are dropped.\n",
    "\n",
    "Below we compare 3 representative wavelength channels before and after binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "BIN_SIZE = 5\n\nairs_binned = bin_time(airs_cmc, bin_size=BIN_SIZE)  # (n_time // BIN_SIZE, n_chan)\n\nn_time_binned = airs_binned.shape[0]\nexpected_snr_gain = np.sqrt(BIN_SIZE)\n\nprint(f\"Before binning : {airs_cmc.shape[0]} time steps\")\nprint(f\"After binning  : {n_time_binned} time steps  (bin_size={BIN_SIZE})\")\nprint(f\"Expected SNR gain (white noise): √{BIN_SIZE} = {expected_snr_gain:.3f}×\")\n\n# Representative channels: first, middle, last\nn_chan = airs_cmc.shape[1]\nchan_indices = [0, n_chan // 2, n_chan - 1]\nchan_labels  = [\"Channel 0 (blue edge)\", f\"Channel {n_chan // 2} (middle)\",\n                f\"Channel {n_chan - 1} (red edge)\"]\n\nt_before = np.arange(airs_cmc.shape[0])\nt_after  = np.arange(n_time_binned) * BIN_SIZE + BIN_SIZE / 2  # centre of each bin\n\nfig, axes = plt.subplots(3, 2, figsize=(14, 10), sharex=False)\nfig.suptitle(\n    f\"Time Binning (bin_size={BIN_SIZE})  |  Expected SNR gain ≈ √{BIN_SIZE} = {expected_snr_gain:.2f}×\",\n    fontsize=13, fontweight=\"bold\"\n)\n\nfor row, (ci, cl) in enumerate(zip(chan_indices, chan_labels)):\n    raw_lc  = airs_cmc[:, ci]\n    bin_lc  = airs_binned[:, ci]\n\n    # Empirical noise (OOT std) before and after binning\n    # For binned mask, approximate: frame i is OOT if it was majority OOT\n    mask_binned = bin_time(mask_oot.astype(np.float32), BIN_SIZE) > 0.5\n\n    noise_before = raw_lc[mask_oot].std() if mask_oot.sum() > 1 else np.nan\n    noise_after  = bin_lc[mask_binned].std() if mask_binned.sum() > 1 else np.nan\n    actual_gain  = noise_before / noise_after if noise_after > 0 else np.nan\n\n    ax_left  = axes[row, 0]\n    ax_right = axes[row, 1]\n\n    # Before\n    ax_left.plot(t_before, raw_lc, lw=0.6, color=\"steelblue\", alpha=0.85)\n    ax_left.fill_between(t_before, raw_lc.min(), raw_lc.max(),\n                         where=~mask_oot, color=\"tomato\", alpha=0.1)\n    ax_left.set_title(f\"{cl} — Before (σ_OOT={noise_before:.5f})\", fontsize=9)\n    ax_left.set_xlabel(\"Time index\", fontsize=8)\n    ax_left.set_ylabel(\"Flux\", fontsize=8)\n    ax_left.tick_params(labelsize=7)\n\n    # After\n    ax_right.plot(t_after, bin_lc, lw=1.0, color=\"darkorchid\", alpha=0.9,\n                  marker=\"o\", markersize=2)\n    ax_right.fill_between(t_after, bin_lc.min(), bin_lc.max(),\n                          where=~mask_binned, color=\"tomato\", alpha=0.1)\n    ax_right.set_title(\n        f\"{cl} — After binning (σ_OOT={noise_after:.5f}, gain={actual_gain:.2f}×)\",\n        fontsize=9\n    )\n    ax_right.set_xlabel(\"Time index (bin centres)\", fontsize=8)\n    ax_right.set_ylabel(\"Flux\", fontsize=8)\n    ax_right.tick_params(labelsize=7)\n\nplt.tight_layout()\nfig.savefig(FIG_DIR / \"step4_time_binning.png\", bbox_inches=\"tight\")\nplt.show()\n\nprint(f\"AIRS binned shape : {airs_binned.shape}\")\nprint(f\"[Done] Temporal binning done. Expected SNR gain ≈ {expected_snr_gain:.3f}×.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Transit Depth Extraction\n",
    "\n",
    "The **transit depth** at wavelength λ is:\n",
    "\n",
    "$$d[\\lambda] = 1 - \\langle F_{\\text{norm}}[\\text{in-transit}, \\lambda] \\rangle$$\n",
    "\n",
    "This equals the fraction of stellar light blocked by the planet's cross-section at that wavelength.  \n",
    "When the atmosphere absorbs at a specific wavelength, the planet appears larger → deeper transit → higher `d[λ]`.\n",
    "\n",
    "Plotting `d[λ]` vs wavelength gives the planet's **transmission spectrum** — the target the model must learn to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Binned OOT mask (same as computed in Step 4)\nmask_binned = bin_time(mask_oot.astype(np.float32), BIN_SIZE) > 0.5\n\n# Extract transit depth for every wavelength channel\ndepth, depth_err = extract_transit_depth(airs_binned, mask_binned)\n\nn_chan = airs_binned.shape[1]\nchan_axis = np.arange(n_chan)\n\nprint(f\"Wavelength channels : {n_chan}\")\nprint(f\"depth shape         : {depth.shape}\")\nprint(f\"depth_err shape     : {depth_err.shape}\")\nprint(f\"Median transit depth: {np.median(depth):.5f}\")\nprint(f\"Min / Max depth     : {depth.min():.5f} / {depth.max():.5f}\")\nprint(f\"Median 1σ error     : {np.median(depth_err):.5f}\")\n\nfig, axes = plt.subplots(2, 1, figsize=(13, 8))\nfig.suptitle(\n    f\"Transit Depth Spectrum — planet '{planet_id}'\",\n    fontsize=13, fontweight=\"bold\"\n)\n\n# ── Top: spectrum with error bars ─────────────────────────────────────────\nax0 = axes[0]\nax0.errorbar(\n    chan_axis, depth, yerr=depth_err,\n    fmt=\"o\", markersize=2, lw=0.5, capsize=1.5,\n    color=\"steelblue\", ecolor=\"lightsteelblue\", alpha=0.85,\n    label=\"Transit depth ± 1σ\"\n)\nax0.axhline(np.median(depth), color=\"darkorange\", lw=1.2, linestyle=\"--\",\n            label=f\"Median depth = {np.median(depth):.5f}\")\nax0.set_xlabel(\"Wavelength channel index\", fontsize=10)\nax0.set_ylabel(\"Transit depth  d[λ] = 1 − ⟨F_in⟩\", fontsize=10)\nax0.set_title(\"Per-channel transit depth (this is the target the model must predict)\", fontsize=10)\nax0.legend(fontsize=9)\n\n# ── Bottom: SNR per channel = depth / depth_err ───────────────────────────\nax1 = axes[1]\nsnr = np.where(depth_err > 0, depth / depth_err, 0.0)\nax1.plot(chan_axis, snr, lw=0.8, color=\"darkorchid\", alpha=0.85)\nax1.axhline(np.median(snr), color=\"darkorange\", lw=1.2, linestyle=\"--\",\n            label=f\"Median SNR = {np.median(snr):.1f}\")\nax1.set_xlabel(\"Wavelength channel index\", fontsize=10)\nax1.set_ylabel(\"SNR = depth / depth_err\", fontsize=10)\nax1.set_title(\"Signal-to-noise ratio per wavelength channel\", fontsize=10)\nax1.legend(fontsize=9)\n\nplt.tight_layout()\nfig.savefig(FIG_DIR / \"step5_transit_depth_spectrum.png\", bbox_inches=\"tight\")\nplt.show()\n\nprint(f\"[Done] Transit depth spectrum extracted: {n_chan} channels, median depth={np.median(depth):.5f}, \"\n      f\"median SNR={np.median(snr):.1f}.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pipeline: `preprocess_planet()`\n",
    "\n",
    "All five steps above are wrapped into the single function `preprocess_planet()`. Running it should produce results identical to the step-by-step walkthrough above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the one-liner full pipeline\n",
    "result = preprocess_planet(\n",
    "    airs,\n",
    "    fgs1,\n",
    "    ingress=INGRESS,\n",
    "    egress=EGRESS,\n",
    "    bin_size=BIN_SIZE,\n",
    ")\n",
    "\n",
    "# ── Inspect output dict ────────────────────────────────────────────────────\n",
    "print(\"preprocess_planet() output keys and shapes:\")\n",
    "print(\"-\" * 50)\n",
    "for key, val in result.items():\n",
    "    arr = np.asarray(val)\n",
    "    print(f\"  {key:<22} shape={arr.shape}  dtype={arr.dtype}\")\n",
    "\n",
    "# ── Verify consistency with step-by-step ──────────────────────────────────\n",
    "print(\"\\nConsistency checks (pipeline result vs step-by-step):\")\n",
    "\n",
    "depth_pipeline = result[\"transit_depth\"]\n",
    "max_diff_depth = np.max(np.abs(depth_pipeline - depth))\n",
    "print(f\"  max |depth_pipeline - depth_stepwise| = {max_diff_depth:.2e}  \"\n",
    "      f\"({'PASS' if max_diff_depth < 1e-10 else 'MISMATCH — investigate!'})\")\n",
    "\n",
    "airs_norm_pipeline = result[\"airs_norm\"]\n",
    "max_diff_airs = np.max(np.abs(airs_norm_pipeline - airs_binned))\n",
    "print(f\"  max |airs_norm_pipeline - airs_binned_stepwise| = {max_diff_airs:.2e}  \"\n",
    "      f\"({'PASS' if max_diff_airs < 1e-10 else 'MISMATCH — investigate!'})\")\n",
    "\n",
    "mask_pipeline = result[\"mask_oot\"]\n",
    "mask_match = np.array_equal(mask_pipeline, mask_binned)\n",
    "print(f\"  mask_oot identical: {mask_match}  \"\n",
    "      f\"({'PASS' if mask_match else 'MISMATCH — investigate!'})\")\n",
    "\n",
    "print(f\"\\n[Done] Full pipeline result: {len(result)} keys, \"\n",
    "      f\"AIRS shape={result['airs_norm'].shape}, FGS1 shape={result['fgs1_norm'].shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Output Visualisation\n",
    "\n",
    "Final combined plot: normalised + binned AIRS white-light curve and FGS1 curve, alongside the extracted transit depth spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "airs_out    = result[\"airs_norm\"]          # (n_time_bin, n_chan)\nfgs1_out    = result[\"fgs1_norm\"]          # (n_time_bin,)\ndepth_out   = result[\"transit_depth\"]      # (n_chan,)\nerr_out     = result[\"transit_depth_err\"]  # (n_chan,)\nmask_out    = result[\"mask_oot\"]           # (n_time_bin,)\n\nn_time_bin  = airs_out.shape[0]\nn_chan       = airs_out.shape[1]\nt_bin        = np.arange(n_time_bin)\nchan_ax      = np.arange(n_chan)\n\nairs_white_out = airs_out.mean(axis=1)\n\nfig, axes = plt.subplots(3, 1, figsize=(13, 11))\nfig.suptitle(\n    f\"Full Preprocessing Pipeline Output — planet '{planet_id}'\",\n    fontsize=13, fontweight=\"bold\"\n)\n\n# ── Binned AIRS white-light ────────────────────────────────────────────────\nax0 = axes[0]\nax0.plot(t_bin, airs_white_out, lw=1.0, color=\"steelblue\", marker=\"o\", markersize=2.5,\n         label=\"AIRS white-light (binned, CMC-corrected)\")\nax0.axhline(1.0, color=\"darkgreen\", lw=1.0, linestyle=\"--\", alpha=0.7)\nax0.fill_between(t_bin, airs_white_out.min() * 0.9998, 1.0002,\n                 where=~mask_out, color=\"tomato\", alpha=0.12, label=\"In-transit\")\nax0.set_ylabel(\"Normalised flux\", fontsize=10)\nax0.set_title(f\"AIRS-CH0 white-light — {n_time_bin} binned frames (bin_size={BIN_SIZE})\", fontsize=10)\nax0.legend(fontsize=8)\n\n# ── Binned FGS1 ───────────────────────────────────────────────────────────\nax1 = axes[1]\nax1.plot(t_bin, fgs1_out, lw=1.0, color=\"darkorange\", marker=\"o\", markersize=2.5,\n         label=\"FGS1 (binned, baseline-normalised)\")\nax1.axhline(1.0, color=\"darkgreen\", lw=1.0, linestyle=\"--\", alpha=0.7)\nax1.fill_between(t_bin, fgs1_out.min() * 0.9998, 1.0002,\n                 where=~mask_out, color=\"tomato\", alpha=0.12, label=\"In-transit\")\nax1.set_ylabel(\"Normalised flux\", fontsize=10)\nax1.set_title(f\"FGS1 broadband — {n_time_bin} binned frames (bin_size={BIN_SIZE})\", fontsize=10)\nax1.legend(fontsize=8)\n\n# ── Transit depth spectrum ─────────────────────────────────────────────────\nax2 = axes[2]\nax2.errorbar(\n    chan_ax, depth_out, yerr=err_out,\n    fmt=\"o\", markersize=2, lw=0.5, capsize=1.5,\n    color=\"steelblue\", ecolor=\"lightsteelblue\", alpha=0.85,\n    label=\"Transit depth ± 1σ  (MODEL TARGET)\"\n)\nax2.axhline(np.median(depth_out), color=\"darkorange\", lw=1.2, linestyle=\"--\",\n            label=f\"Median = {np.median(depth_out):.5f}\")\nax2.set_xlabel(\"Wavelength channel index  (0 = 1.95 µm, 355 = 3.90 µm)\", fontsize=10)\nax2.set_ylabel(\"Transit depth  1 − ⟨F_in⟩\", fontsize=10)\nax2.set_title(\"Extracted transit depth spectrum — this is what the model learns to predict\",\n              fontsize=10)\nax2.legend(fontsize=8)\n\nplt.tight_layout()\nfig.savefig(FIG_DIR / \"step6_full_pipeline_output.png\", bbox_inches=\"tight\")\nplt.show()\n\nprint(f\"[Done] Full pipeline visualisation complete for planet '{planet_id}'.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n### What each preprocessing step achieves and why it matters\n\n- **Step 0 — Detector calibration (raw parquet → calibrated numpy)**\n  - Loads raw uint16 detector frames from per-planet parquet files.\n  - **Dark subtraction**: removes thermal electron current accumulated during readout.\n  - **Flat-field division**: corrects for per-pixel sensitivity variations across the detector.\n  - **Dead pixel zeroing**: masks hot/dead pixels to prevent them from corrupting the signal.\n  - **Spatial summation**: collapses the 2-D detector image (32 spatial rows for AIRS, 32x32 pixels for FGS1) into 1-D light curves per spectral channel.\n  - **FGS1 downsampling**: averages every 12 FGS1 frames to match the AIRS cadence (135,000 → 11,250 frames).\n  - This \"Step 0\" converts ~180 GB of raw detector data into clean `(n_time, 356)` AIRS and `(n_time,)` FGS1 arrays ready for signal processing.\n\n- **Step 1 — Out-of-transit (OOT) mask**\n  - Separates frames where the planet is in front of the star from those where it is not.\n  - The OOT frames serve as the *reference baseline* for all subsequent normalisation steps.\n  - Without this mask, in-transit frames would contaminate the baseline and bias the measured depths.\n\n- **Step 2 — Baseline normalisation**\n  - Divides each wavelength channel by its OOT median, making every channel dimensionless and centred near 1.0.\n  - Removes channel-to-channel gain differences (quantum efficiency variations, detector non-uniformity).\n  - After this step, in-transit flux dipping below 1.0 directly represents the atmospheric absorption signal.\n\n- **Step 3 — Common-mode correction**\n  - Removes correlated systematics shared across all wavelengths simultaneously: telescope jitter, PSF breathing, stellar variability.\n  - Divides each time-step by the wavelength-mean of that step (the \"common mode\").\n  - **Critical detail**: in-transit common-mode values are clamped to the OOT mean before dividing. This prevents accidental cancellation of the transit signal (which dips in-transit) against itself.\n  - After this step, only wavelength-specific signals — atmospheric absorption features — remain.\n\n- **Step 4 — Temporal binning**\n  - Co-adds every `bin_size` consecutive frames, reducing the time axis by a factor of `bin_size`.\n  - Reduces photon noise by sqrt(`bin_size`) (approx 2.24x for `bin_size=5`) at the cost of temporal resolution.\n  - Lowers the feature dimensionality for downstream ML models and speeds up training.\n\n- **Step 5 — Transit depth extraction**\n  - Computes `d[lam] = 1 - mean(F_in-transit[lam])` for each wavelength channel independently.\n  - Produces the **transmission spectrum**: the planet's apparent radius as a function of wavelength.\n  - This 356-element vector (after binning to 283 competition targets) is what the ML model must predict.\n  - The 1-sigma uncertainty (standard error of the in-transit mean) quantifies per-channel measurement noise.\n\n### Why this pipeline matters for the model\n\n- The raw AIRS parquet contains `(~11,250 time steps x 32 spatial rows x 356 channels)` — over 128 million numbers per planet.\n- After calibration, spatial summation, and preprocessing, the transmission spectrum is just **356 numbers** — a massive compression that retains the scientifically relevant signal.\n- The competition metric (Gaussian log-likelihood on predicted mean and std per wavelength) requires well-calibrated uncertainty estimates, making the `depth_err` output directly useful.\n- Baseline and common-mode corrections are standard photometric reduction steps used in real transit spectroscopy (e.g., Hubble WFC3, JWST NIRSpec pipelines).\n- Auxiliary information is provided as 5 ADC features per planet (ADC gain/offset for AIRS and FGS1, plus star type) from `train_adc_info.csv`."
  },
  {
   "cell_type": "markdown",
   "id": "xnrln3hglnr",
   "source": "## Push Preprocessing Figures to GitHub\n\nPush the 6 step-by-step preprocessing plots to the repo so they can be reviewed without re-running the notebook.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6ucs03ncmic",
   "source": "import shutil\nimport subprocess\nfrom pathlib import Path\n\n# ── GitHub token for pushing (paste your PAT here) ────────────────────────\n# Generate at: https://github.com/settings/tokens → Fine-grained → repo:write\nGH_TOKEN = \"\"  # <-- paste your GitHub PAT here\n\n# ── Repo paths ────────────────────────────────────────────────────────────\nrepo_dir    = Path(\"/kaggle/working/ariel-exoplanet-ml\")\nproject_dir = repo_dir / \"Kaggle competition\" / \"ARIEL neurIPS\"\n\n# ── Ensure repo is up-to-date ─────────────────────────────────────────────\nif not repo_dir.exists():\n    subprocess.run(\n        [\"git\", \"clone\", \"https://github.com/Smooth-Cactus0/ariel-exoplanet-ml.git\",\n         str(repo_dir)],\n        check=True,\n    )\nelse:\n    subprocess.run([\"git\", \"-C\", str(repo_dir), \"pull\", \"--ff-only\"], check=False)\n\n# ── Configure git identity (required on Kaggle kernels) ───────────────────\nsubprocess.run([\"git\", \"-C\", str(repo_dir), \"config\", \"user.email\", \"alexy.louis@kaggle-notebook.local\"], check=True)\nsubprocess.run([\"git\", \"-C\", str(repo_dir), \"config\", \"user.name\", \"Alexy Louis (Kaggle)\"], check=True)\n\n# ── Copy preprocessing figures to repo ─────────────────────────────────────\nrepo_fig_dir = project_dir / \"figures\"\nrepo_fig_dir.mkdir(parents=True, exist_ok=True)\n\nfigure_files = sorted(FIG_DIR.glob(\"*.png\"))\nprint(f\"Found {len(figure_files)} figures in {FIG_DIR}:\")\nfor fig_path in figure_files:\n    dest = repo_fig_dir / fig_path.name\n    shutil.copy2(fig_path, dest)\n    print(f\"  {fig_path.name} -> figures/{fig_path.name}\")\n\n# ── Git add, commit, push ─────────────────────────────────────────────────\nsubprocess.run(\n    [\"git\", \"-C\", str(repo_dir), \"add\",\n     \"Kaggle competition/ARIEL neurIPS/figures/\"],\n    check=True,\n)\n\nstatus = subprocess.run(\n    [\"git\", \"-C\", str(repo_dir), \"diff\", \"--cached\", \"--quiet\"],\n    capture_output=True,\n)\nif status.returncode != 0:\n    subprocess.run(\n        [\"git\", \"-C\", str(repo_dir), \"commit\", \"-m\",\n         \"data: update preprocessing figures from Kaggle notebook run\"],\n        check=True,\n    )\n    # Set authenticated remote URL for push\n    if GH_TOKEN:\n        subprocess.run(\n            [\"git\", \"-C\", str(repo_dir), \"remote\", \"set-url\", \"origin\",\n             f\"https://{GH_TOKEN}@github.com/Smooth-Cactus0/ariel-exoplanet-ml.git\"],\n            check=True,\n        )\n    subprocess.run(\n        [\"git\", \"-C\", str(repo_dir), \"push\", \"origin\", \"master\"],\n        check=True,\n    )\n    print(\"\\n[Done] Preprocessing figures pushed to GitHub.\")\nelse:\n    print(\"\\n[Done] No changes to push (figures already up-to-date).\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}