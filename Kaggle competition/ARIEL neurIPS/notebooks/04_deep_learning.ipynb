{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": "# NeurIPS 2024 Ariel Data Challenge — Deep Learning Training\n\n**Goal**: Train `TransitCNN` end-to-end on preprocessed Ariel light curves to predict\n283-wavelength atmospheric transmission spectra with calibrated uncertainty.\n\n**Scoring**: Gaussian Log-Likelihood (GLL). Higher is better; 0 = perfect.\n\n**Architecture**: `TransitCNN` — dual 1-D CNN encoders (AIRS-CH0 + FGS1) fused with\n5 ADC calibration features, producing `(mean, log_var)` per output wavelength.\nSigma is learned purely from GLL loss (no supervised sigma targets).\n\n> **Note**: This notebook is Kaggle-ready and requires the `ariel-data-challenge-2024`\n> dataset attached to the kernel, plus the cloned repo at\n> `/kaggle/working/ariel-exoplanet-ml/`."
  },
  {
   "cell_type": "markdown",
   "id": "md-sec1",
   "metadata": {},
   "source": [
    "## 1. Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-clone-repo",
   "metadata": {},
   "outputs": [],
   "source": "import subprocess\nimport sys\nfrom pathlib import Path\n\n# ── Clone the repo on Kaggle and add to sys.path ──────────────────────────\nrepo_dir = \"/kaggle/working/ariel-exoplanet-ml\"\nproject_dir = repo_dir + \"/Kaggle competition/ARIEL neurIPS\"\n\nif not Path(repo_dir).exists():\n    subprocess.run(\n        [\"git\", \"clone\", \"https://github.com/Smooth-Cactus0/ariel-exoplanet-ml.git\", repo_dir],\n        check=True,\n    )\n    print(f\"Cloned repo to {repo_dir}\")\nelse:\n    print(f\"Repo already exists at {repo_dir}\")\n\n# Add project root to Python path so `src.*` imports resolve.\nif project_dir not in sys.path:\n    sys.path.insert(0, project_dir)\n\nprint(f\"sys.path[0] = {sys.path[0]}\")\nprint(\"[Done] repo path configured.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gpu-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ── Random seed (reproducibility) ─────────────────────────────────────────\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ── Device ────────────────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version : {torch.__version__}\")\n",
    "print(f\"Device          : {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name        : {torch.cuda.get_device_name(0)}\")\n",
    "    vram_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"GPU VRAM        : {vram_gb:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU found — training will be slow on CPU.\")\n",
    "\n",
    "# ── Paths ──────────────────────────────────────────────────────────────────\n",
    "DATA_ROOT = Path(\"/kaggle/input/ariel-data-challenge-2024\")\n",
    "OUT_DIR   = Path(\"/kaggle/working/outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nDATA_ROOT : {DATA_ROOT}\")\n",
    "print(f\"OUT_DIR   : {OUT_DIR}\")\n",
    "print(\"[Done] Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-sec2",
   "metadata": {},
   "source": [
    "## 2. Dataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dataset",
   "metadata": {},
   "outputs": [],
   "source": "from torch.utils.data import DataLoader, random_split\n\nfrom src.dataset import ArielDataset\nfrom src.train import make_labelled_subset\n\n# ── Full training dataset (all planets, labelled + unlabelled) ─────────────\nfull_train_ds = ArielDataset(\n    DATA_ROOT,\n    split=\"train\",\n    bin_size=5,\n    preprocess=True,\n)\nprint(f\"Total planets in train directory : {len(full_train_ds)}\")\n\n# ── Labelled subset (only planets with train_labels.csv ground truth) ──────\nlabelled_ds = make_labelled_subset(full_train_ds)\nn_labelled = len(labelled_ds)\nprint(f\"Labelled planets                 : {n_labelled}\")\nprint(f\"  (~{100 * n_labelled / len(full_train_ds):.1f}% of total)\")\n\n# ── 80 / 20 train / val split ──────────────────────────────────────────────\nn_val   = max(1, int(n_labelled * 0.20))\nn_train = n_labelled - n_val\n\ntrain_ds, val_ds = random_split(\n    labelled_ds,\n    [n_train, n_val],\n    generator=torch.Generator().manual_seed(SEED),\n)\nprint(f\"Train split                      : {n_train}\")\nprint(f\"Val split                        : {n_val}\")\n\n# ── DataLoaders ────────────────────────────────────────────────────────────\ntrain_loader = DataLoader(\n    train_ds,\n    batch_size=32,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=(device.type == \"cuda\"),\n)\nval_loader = DataLoader(\n    val_ds,\n    batch_size=32,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=(device.type == \"cuda\"),\n)\n\nprint(f\"\\nTrain batches : {len(train_loader)}\")\nprint(f\"Val batches   : {len(val_loader)}\")\n\n# ── Inspect one batch ──────────────────────────────────────────────────────\nsample_batch = next(iter(train_loader))\nprint(\"\\nSample batch shapes:\")\nfor k, v in sample_batch.items():\n    if hasattr(v, 'shape'):\n        print(f\"  {k:15s}: {tuple(v.shape)}  dtype={v.dtype}\")\n    else:\n        print(f\"  {k:15s}: {type(v).__name__} (len={len(v)})\")\n\nprint(\"[Done] Datasets and loaders ready.\")"
  },
  {
   "cell_type": "markdown",
   "id": "md-sec3",
   "metadata": {},
   "source": [
    "## 3. Model Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-model-init",
   "metadata": {},
   "outputs": [],
   "source": "from src.model import TransitCNN\n\n# ── Instantiate TransitCNN ────────────────────────────────────────────────\n# n_aux=5: the 5 ADC calibration features from train_adc_info.csv\n#   (FGS1_adc_offset, FGS1_adc_gain, AIRS-CH0_adc_offset, AIRS-CH0_adc_gain, star)\nmodel = TransitCNN(\n    embed_dim=128,\n    dropout=0.1,\n    n_aux=5,\n    n_output_wl=283,\n).to(device)\n\n# ── Parameter count ───────────────────────────────────────────────────────\nn_params       = sum(p.numel() for p in model.parameters())\nn_trainable    = sum(p.numel() for p in model.parameters() if p.requires_grad)\nn_non_trainable = n_params - n_trainable\n\nprint(f\"Total parameters       : {n_params:>10,}\")\nprint(f\"Trainable parameters   : {n_trainable:>10,}\")\nprint(f\"Non-trainable params   : {n_non_trainable:>10,}\")\n\n# ── Architecture summary (top-level named children) ──────────────────────\nprint(\"\\nTop-level modules:\")\nprint(f\"{'Module name':<20} {'Class':<25} {'# params':>10}\")\nprint(\"-\" * 58)\nfor name, module in model.named_children():\n    n_mod = sum(p.numel() for p in module.parameters())\n    print(f\"{name:<20} {type(module).__name__:<25} {n_mod:>10,}\")\n\n# ── Quick forward-pass smoke test ─────────────────────────────────────────\nmodel.eval()\nwith torch.no_grad():\n    test_airs = sample_batch[\"airs\"].to(device)\n    test_fgs1 = sample_batch[\"fgs1\"].to(device)\n    test_aux  = sample_batch[\"aux\"].to(device)\n    test_mean, test_log_var = model(test_airs, test_fgs1, test_aux)\n\nprint(f\"\\nSmoke-test output shapes:\")\nprint(f\"  mean    : {tuple(test_mean.shape)}\")\nprint(f\"  log_var : {tuple(test_log_var.shape)}\")\n\nprint(\"[Done] Model instantiated and smoke test passed.\")"
  },
  {
   "cell_type": "markdown",
   "id": "md-sec4",
   "metadata": {},
   "source": [
    "## 4. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# ── Hyperparameter config ─────────────────────────────────────────────────\n",
    "config = dict(\n",
    "    lr              = 3e-4,\n",
    "    weight_decay    = 1e-4,\n",
    "    epochs          = 50,\n",
    "    clip_grad       = 1.0,\n",
    "    scheduler       = \"cosine\",\n",
    "    checkpoint_dir  = OUT_DIR / \"checkpoints\",\n",
    ")\n",
    "config[\"checkpoint_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for k, v in config.items():\n",
    "    print(f\"  {k:<20}: {v}\")\n",
    "\n",
    "# ── Optimizer ────────────────────────────────────────────────────────────\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config[\"lr\"],\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "# ── LR scheduler: cosine annealing to lr*0.01 at T_max ───────────────────\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config[\"epochs\"],\n",
    "    eta_min=config[\"lr\"] * 0.01,\n",
    ")\n",
    "\n",
    "print(f\"\\nOptimizer : {type(optimizer).__name__}\")\n",
    "print(f\"Scheduler : {type(scheduler).__name__}  (T_max={config['epochs']}, \"\n",
    "      f\"eta_min={config['lr'] * 0.01:.2e})\")\n",
    "print(\"[Done] Optimizer and scheduler configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-sec5",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-training-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.model import gaussian_nll_loss\n",
    "from src.train import train_epoch, eval_epoch\n",
    "\n",
    "# ── History containers ────────────────────────────────────────────────────\n",
    "train_losses: list[float] = []\n",
    "val_glls:     list[float] = []\n",
    "\n",
    "best_val_gll   = float(\"-inf\")   # GLL: higher is better\n",
    "best_ckpt_path = config[\"checkpoint_dir\"] / \"best_model.pt\"\n",
    "\n",
    "print(f\"Starting training for {config['epochs']} epochs ...\\n\")\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(1, config[\"epochs\"] + 1):\n",
    "    # ── Train ──────────────────────────────────────────────────────────────\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "\n",
    "    # ── Validate ───────────────────────────────────────────────────────────\n",
    "    # eval_epoch returns the negative-NLL loss value;\n",
    "    # we negate it to get a GLL-style score (higher = better).\n",
    "    val_nll  = eval_epoch(model, val_loader, device)\n",
    "    val_gll  = -val_nll  # approximate GLL: higher is better\n",
    "\n",
    "    # ── LR scheduler step ─────────────────────────────────────────────────\n",
    "    scheduler.step()\n",
    "    lr_now = scheduler.get_last_lr()[0]\n",
    "\n",
    "    # ── Record history ────────────────────────────────────────────────────\n",
    "    train_losses.append(train_loss)\n",
    "    val_glls.append(val_gll)\n",
    "\n",
    "    # ── Save best checkpoint ───────────────────────────────────────────────\n",
    "    improved = \"\"\n",
    "    if val_gll > best_val_gll:\n",
    "        best_val_gll = val_gll\n",
    "        torch.save(model.state_dict(), best_ckpt_path)\n",
    "        improved = \"  <- best\"\n",
    "\n",
    "    # ── Log ───────────────────────────────────────────────────────────────\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d}/{config['epochs']}  \"\n",
    "        f\"train_loss={train_loss:.4f}  \"\n",
    "        f\"val_GLL={val_gll:.4f}  \"\n",
    "        f\"lr={lr_now:.2e}\"\n",
    "        f\"{improved}\"\n",
    "    )\n",
    "\n",
    "# ── Save final checkpoint and history ────────────────────────────────────\n",
    "last_ckpt_path = config[\"checkpoint_dir\"] / \"last_model.pt\"\n",
    "torch.save(model.state_dict(), last_ckpt_path)\n",
    "\n",
    "history = [\n",
    "    {\"epoch\": e + 1, \"train_loss\": tl, \"val_gll\": vg}\n",
    "    for e, (tl, vg) in enumerate(zip(train_losses, val_glls))\n",
    "]\n",
    "with open(config[\"checkpoint_dir\"] / \"history.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nTraining complete in {elapsed / 60:.1f} min.\")\n",
    "print(f\"Best val GLL : {best_val_gll:.4f}\")\n",
    "print(f\"Checkpoints  : {config['checkpoint_dir']}\")\n",
    "print(\"[Done] Training loop finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-training-curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Plot training curves ──────────────────────────────────────────────────\n",
    "epochs_range = list(range(1, len(train_losses) + 1))\n",
    "\n",
    "fig, (ax_loss, ax_gll) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle(\"TransitCNN Training Curves\", fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "# Left: train loss\n",
    "ax_loss.plot(epochs_range, train_losses, color=\"steelblue\", lw=1.5, label=\"Train NLL loss\")\n",
    "ax_loss.set_xlabel(\"Epoch\", fontsize=11)\n",
    "ax_loss.set_ylabel(\"Gaussian NLL Loss\", fontsize=11)\n",
    "ax_loss.set_title(\"Training Loss (NLL)\", fontsize=11)\n",
    "ax_loss.legend(fontsize=9)\n",
    "ax_loss.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: val GLL\n",
    "ax_gll.plot(epochs_range, val_glls, color=\"darkorange\", lw=1.5, label=\"Val GLL\")\n",
    "best_epoch = int(np.argmax(val_glls)) + 1\n",
    "ax_gll.axvline(best_epoch, color=\"red\", linestyle=\"--\", lw=1.2,\n",
    "               label=f\"Best epoch={best_epoch} (GLL={best_val_gll:.4f})\")\n",
    "ax_gll.set_xlabel(\"Epoch\", fontsize=11)\n",
    "ax_gll.set_ylabel(\"Val GLL (higher is better)\", fontsize=11)\n",
    "ax_gll.set_title(\"Validation Gaussian Log-Likelihood\", fontsize=11)\n",
    "ax_gll.legend(fontsize=9)\n",
    "ax_gll.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"training_curves.png\", dpi=120, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"[Done] Training curves saved to {OUT_DIR / 'training_curves.png'}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-sec6",
   "metadata": {},
   "source": [
    "## 6. Load Best Checkpoint & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load-best",
   "metadata": {},
   "outputs": [],
   "source": "from src.evaluate import run_inference, gaussian_log_likelihood\n\n# ── Load best checkpoint ──────────────────────────────────────────────────\nprint(f\"Loading best checkpoint from: {best_ckpt_path}\")\nstate_dict = torch.load(best_ckpt_path, map_location=device)\nmodel.load_state_dict(state_dict)\nmodel.eval()\nprint(\"Checkpoint loaded successfully.\")\n\n# ── Run inference on the validation loader ────────────────────────────────\nplanet_ids_val, means_val, stds_val = run_inference(model, val_loader, device)\nprint(f\"\\nVal inference: {len(planet_ids_val)} planets  \"\n      f\"| means shape={means_val.shape}  | stds shape={stds_val.shape}\")\n\n# ── Gather ground-truth mean spectra for GLL computation ─────────────────\n# Labels format (train_labels.csv): planet_id | wl_1 | wl_2 | ... | wl_283\nwl_cols = [f\"wl_{i}\" for i in range(1, 284)]\ngt_mean_list = []\nfor pid in planet_ids_val:\n    row = full_train_ds.labels.loc[int(pid)]\n    gt_mean_list.append(row[wl_cols].values.astype(np.float32))\ngt_means = np.stack(gt_mean_list)   # (n_val, 283)\n\n# ── Final GLL ─────────────────────────────────────────────────────────────\nfinal_val_gll = gaussian_log_likelihood(gt_means, means_val, stds_val)\nprint(f\"\\nFinal val GLL (best model): {final_val_gll:.4f}\")\nprint(\"  (GLL = 0 is perfect; more negative = worse)\")\nprint(\"[Done] Evaluation complete.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-spectrum-plots",
   "metadata": {},
   "outputs": [],
   "source": "# ── Plot predicted vs ground-truth spectra for 3 example val planets ──────\n# Subplot grid: 3 rows x 2 columns\n# Left column : full-spectrum view (GT mean vs predicted mean +/- sigma)\n# Right column: zoomed residual view\n\nN_EXAMPLES = 3\nwl_idx = np.arange(283)\n\nfig, axes = plt.subplots(N_EXAMPLES, 2, figsize=(16, 5 * N_EXAMPLES))\nfig.suptitle(\n    \"Predicted vs Ground-Truth Transmission Spectra\\n\"\n    \"(val set, best checkpoint)\\n\"\n    \"Left: full spectrum  |  Right: residual (pred - GT)\",\n    fontsize=12, fontweight=\"bold\"\n)\n\nfor row_i in range(N_EXAMPLES):\n    pid  = planet_ids_val[row_i]\n    mu   = means_val[row_i]      # (283,)  predicted mean\n    sig  = stds_val[row_i]       # (283,)  predicted std\n\n    # Ground-truth mean spectrum from train_labels.csv (wl_1 ... wl_283)\n    gt_row = full_train_ds.labels.loc[int(pid)]\n    gt_mean = gt_row[wl_cols].values.astype(np.float32)\n\n    # ── Left: full spectrum ───────────────────────────────────────────────\n    ax_l = axes[row_i, 0]\n    ax_l.plot(wl_idx, gt_mean, color=\"steelblue\", lw=1.5, label=\"GT mean\")\n    ax_l.plot(wl_idx, mu, color=\"darkorange\", lw=1.5, linestyle=\"--\",\n              label=\"Predicted mean\")\n    ax_l.fill_between(wl_idx, mu - sig, mu + sig, alpha=0.25,\n                      color=\"darkorange\", label=\"Pred +/-1 sigma\")\n    ax_l.set_xlabel(\"Wavelength index\", fontsize=9)\n    ax_l.set_ylabel(\"Transmission depth\", fontsize=9)\n    ax_l.set_title(f\"Planet {pid} — spectrum\", fontsize=9, fontweight=\"bold\")\n    ax_l.legend(fontsize=7, loc=\"upper right\")\n    ax_l.grid(True, alpha=0.3)\n\n    # ── Right: residual ───────────────────────────────────────────────────\n    ax_r = axes[row_i, 1]\n    residual    = mu - gt_mean\n    norm_resid  = residual / np.clip(sig, 1e-9, None)\n    ax_r.bar(wl_idx, norm_resid, width=1.0, color=\"purple\", alpha=0.5,\n             label=\"(pred - GT) / pred_std\")\n    ax_r.axhline(0,  color=\"black\",  lw=1.0)\n    ax_r.axhline(+1, color=\"red\",    lw=0.8, linestyle=\":\")\n    ax_r.axhline(-1, color=\"red\",    lw=0.8, linestyle=\":\")\n    ax_r.set_xlabel(\"Wavelength index\", fontsize=9)\n    ax_r.set_ylabel(\"Normalised residual (sigma)\", fontsize=9)\n    ax_r.set_title(f\"Planet {pid} — residual\", fontsize=9, fontweight=\"bold\")\n    ax_r.legend(fontsize=7, loc=\"upper right\")\n    ax_r.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(OUT_DIR / \"val_spectra_examples.png\", dpi=120, bbox_inches=\"tight\")\nplt.show()\nprint(f\"[Done] Spectrum plots saved to {OUT_DIR / 'val_spectra_examples.png'}.\")"
  },
  {
   "cell_type": "markdown",
   "id": "md-sec7",
   "metadata": {},
   "source": [
    "## 7. Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-submission",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\nfrom src.evaluate import build_submission\n\n# ── Test dataset ──────────────────────────────────────────────────────────\ntest_ds = ArielDataset(\n    DATA_ROOT,\n    split=\"test\",\n    bin_size=5,\n    preprocess=True,\n)\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=64,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=(device.type == \"cuda\"),\n)\nprint(f\"Test planets  : {len(test_ds)}\")\nprint(f\"Test batches  : {len(test_loader)}\")\n\n# ── Run inference on test split ───────────────────────────────────────────\nplanet_ids_test, means_test, stds_test = run_inference(model, test_loader, device)\nprint(f\"\\nTest inference: {len(planet_ids_test)} planets  \"\n      f\"| means={means_test.shape}  | stds={stds_test.shape}\")\n\n# ── Build submission DataFrame ────────────────────────────────────────────\n# Column format: planet_id | wl_1...wl_283 | sigma_1...sigma_283 (567 cols total)\nsub_df = build_submission(planet_ids_test, means_test, stds_test)\n\n# ── Save to disk ──────────────────────────────────────────────────────────\nsubmission_path = Path(\"/kaggle/working/submission.csv\")\nsub_df.to_csv(submission_path, index=False)\n\nprint(f\"\\nSubmission saved: {submission_path}\")\nprint(f\"Shape           : {sub_df.shape}\")\nprint(f\"Columns (first 7): {list(sub_df.columns[:7])}\")\nprint(\"\\nFirst 3 rows:\")\ndisplay(sub_df.head(3))\n\nprint(\"[Done] Submission file written.\")"
  },
  {
   "cell_type": "markdown",
   "id": "md-sec8",
   "metadata": {},
   "source": "## 8. Summary\n\n### Model Architecture\n\n- **TransitCNN**: dual-encoder design processing AIRS-CH0 (IR spectrometer, 356 channels)\n  and FGS1 (visible broadband, 32x32 detector) separately via 3-layer `TemporalEncoder` blocks\n  (Conv1d + GELU + GlobalAvgPool), then fusing both embeddings with 5 ADC calibration features\n  (from `train_adc_info.csv`) through a 3-layer MLP.\n- Two output heads: `mean (283,)` and `log_var (283,)` — one prediction per wavelength bin.\n- Loss: Gaussian NLL, which jointly minimises prediction error and trains calibrated\n  uncertainty. Sigma is learned purely from GLL loss — no supervised sigma targets exist\n  in the training data.\n\n### Data Format\n\n- **Input**: parquet directory per planet with raw detector frames + calibration files\n  (dark, flat, dead pixel mask). Calibrated and collapsed to `(n_time, 356)` AIRS +\n  `(n_time,)` FGS1 time series, then preprocessed (baseline-normalise, common-mode\n  correction, temporal binning).\n- **Labels**: `train_labels.csv` with `wl_1`...`wl_283` mean transmission values only\n  (~24% of training planets labelled).\n- **Auxiliary**: `train_adc_info.csv` with 5 ADC features per planet (FGS1/AIRS\n  gain/offset + star type).\n\n### Training Configuration\n\n| Hyperparameter   | Value          |\n|------------------|----------------|\n| `embed_dim`      | 128            |\n| `dropout`        | 0.1            |\n| `n_aux`          | 5              |\n| `optimizer`      | AdamW          |\n| `lr`             | 3e-4           |\n| `weight_decay`   | 1e-4           |\n| `epochs`         | 50             |\n| `batch_size`     | 32             |\n| `scheduler`      | CosineAnnealing|\n| `clip_grad_norm` | 1.0            |\n| `bin_size`       | 5              |\n| `val_fraction`   | 20%            |\n| `seed`           | 42             |\n\n### Final Validation GLL\n\nSee `final_val_gll` printed in Section 6.  \n(GLL = 0 is perfect; increasingly negative values indicate worse calibration.)\n\n### What to Try Next\n\n- **Ensembling**: train 5 models with different seeds and average their `(mean, log_var)` \n  predictions; ensemble uncertainty can be derived from prediction variance across members.\n- **More augmentation**: apply time-shift jitter, channel dropout, and Gaussian noise\n  injection during training to improve generalisation.\n- **Larger `embed_dim`**: try `embed_dim=256` or `embed_dim=512`; the current bottleneck\n  is the 128-dim AIRS embedding relative to the 356 input channels.\n- **Attention pooling**: replace `AdaptiveAvgPool1d` with a learnable attention-weighted\n  pool to focus on the transit window.\n- **Pseudo-labelling**: use the trained model to generate soft targets for the ~76%\n  unlabelled planets; re-train with a combined labelled + pseudo-labelled dataset.\n- **Physics priors**: add stellar limb-darkening coefficients or Bazin parametric\n  light-curve features as extra auxiliary inputs."
  },
  {
   "cell_type": "markdown",
   "id": "4whcp2f2lt3",
   "source": "## 9. Push Results to GitHub\n\nPush training artifacts (checkpoints, plots, history, submission) back to the repo so\ndownstream notebooks and collaborators can access them without re-training.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "577ewab7s7v",
   "source": "import shutil\nimport subprocess\nfrom pathlib import Path\n\n# ── GitHub token for authenticated push ────────────────────────────────────\nGH_TOKEN = \"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\"\n\n# ── Repo paths ────────────────────────────────────────────────────────────\nrepo_dir    = Path(\"/kaggle/working/ariel-exoplanet-ml\")\nproject_dir = repo_dir / \"Kaggle competition\" / \"ARIEL neurIPS\"\n\n# ── Clone or hard-reset to remote master ──────────────────────────────────\nif not repo_dir.exists():\n    subprocess.run(\n        [\"git\", \"clone\", \"https://github.com/Smooth-Cactus0/ariel-exoplanet-ml.git\", str(repo_dir)],\n        check=True,\n    )\n    print(f\"Cloned repo to {repo_dir}\")\nelse:\n    subprocess.run([\"git\", \"-C\", str(repo_dir), \"fetch\", \"origin\"], check=True)\n    subprocess.run([\"git\", \"-C\", str(repo_dir), \"reset\", \"--hard\", \"origin/master\"], check=True)\n    print(f\"Repo reset to origin/master\")\n\n# ── Configure git identity (required on Kaggle kernels) ───────────────────\nsubprocess.run([\"git\", \"-C\", str(repo_dir), \"config\", \"user.email\", \"alexy.louis@kaggle-notebook.local\"], check=True)\nsubprocess.run([\"git\", \"-C\", str(repo_dir), \"config\", \"user.name\", \"Alexy Louis (Kaggle)\"], check=True)\n\n# ── Define artifact destinations ──────────────────────────────────────────\nresults_dir = project_dir / \"results\"\nresults_dir.mkdir(parents=True, exist_ok=True)\nfigures_dir = project_dir / \"figures\"\nfigures_dir.mkdir(parents=True, exist_ok=True)\n\n# ── Copy artifacts ────────────────────────────────────────────────────────\nOUT_DIR = Path(\"/kaggle/working/outputs\")\nartifacts = {\n    OUT_DIR / \"checkpoints\" / \"best_model.pt\":  results_dir / \"best_model.pt\",\n    OUT_DIR / \"checkpoints\" / \"history.json\":   results_dir / \"history.json\",\n    OUT_DIR / \"training_curves.png\":            figures_dir / \"training_curves.png\",\n    OUT_DIR / \"val_spectra_examples.png\":       figures_dir / \"val_spectra_examples.png\",\n    Path(\"/kaggle/working/submission.csv\"):      results_dir / \"submission.csv\",\n}\n\nfor src, dst in artifacts.items():\n    if src.exists():\n        shutil.copy2(src, dst)\n        print(f\"  {src.name} → {dst.relative_to(project_dir)}  ({src.stat().st_size/1024**2:.1f} MB)\")\n    else:\n        print(f\"  [SKIP] {src} not found\")\n\n# ── Git add, commit, push ─────────────────────────────────────────────────\nsubprocess.run(\n    [\"git\", \"-C\", str(repo_dir), \"add\",\n     \"Kaggle competition/ARIEL neurIPS/results/\",\n     \"Kaggle competition/ARIEL neurIPS/figures/\"],\n    check=True,\n)\n\nstatus = subprocess.run(\n    [\"git\", \"-C\", str(repo_dir), \"diff\", \"--cached\", \"--quiet\"],\n    capture_output=True,\n)\nif status.returncode != 0:\n    subprocess.run(\n        [\"git\", \"-C\", str(repo_dir), \"commit\", \"-m\",\n         \"data: update training results from Kaggle notebook run\"],\n        check=True,\n    )\n    subprocess.run(\n        [\"git\", \"-C\", str(repo_dir), \"remote\", \"set-url\", \"origin\",\n         f\"https://{GH_TOKEN}@github.com/Smooth-Cactus0/ariel-exoplanet-ml.git\"],\n        check=True,\n    )\n    subprocess.run(\n        [\"git\", \"-C\", str(repo_dir), \"push\", \"origin\", \"master\"],\n        check=True,\n    )\n    print(\"\\n[Done] Results pushed to GitHub.\")\nelse:\n    print(\"\\n[Done] No changes to push (artifacts already up-to-date).\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}